\documentclass[12pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\author{Frederik Appel Vardinghus-Nielsen}
\begin{document}
\noindent {\Huge 9 Stochastic simulation}\\\\
\begin{itemize}
\setlength\itemsep{0em}
\item Maybe talk about number generation
\item Define cdf
\item List requirements for inverse cdf
\item Prove the below proposition
\item Prove the Inverse Transformation Method
\end{itemize}
Det ønskes at simulere $U\sim\text{unif}[0,1]$.
\begin{itemize}
\item Approksimér [0,1] ved $\{0,\frac{1}{m},\ldots,\frac{m-1}{m},1\}$ for store $m$
\item Ønskes at simulere $U=\frac{Y}{m}$, $Y\sim\text{unif}\{0,1,\ldots,m\}$
\item Lad $Y_0$ være givet ved et seed\\
Lad $Y_{n+1}=aY_n+b$
\item Så er sekvensen $Y_1,Y_2,\ldots$ en sekvens af i.i.d. RVer $\sim\text{unif}\{0,1,\ldots,m\}$
\end{itemize}
Any discrete distribution $X$ which assumes values $x_1,x_2,\ldots$ with probability $p_1,p_2,\ldots$ can be simulated by parting $U\sim\text{unif}[0,1]$ into subintervals of the $p$'s and assigning $X=x_k$ if $U$ lands in the interval $[p_{k-1},p_k]$.\\\\
\textbf{Proposition 5.1} Consider the pmf $p$ on the range $\{x_1,x_2,\ldots\}$ and let
\begin{equation}
F_0=0,\phantom{m}F_k=\sum_{j=1}^kp(x_k),\phantom{mm}k=1,2,\ldots
\end{equation}
Let $U\sim\text{unif}[0,1]$ and let $X=x_k$ if $F{k-1}<U\leq F_k$. Then $X$ has pmf $p$.
\textbf{Bevis}\\
Note that $X=x_k$ if and only if $U\in (F_{k-1}F_k]$, which has probability
\begin{equation}
P(X=x_k)=P(F_{k-1}<U\leq F_k)=F_k-F_{k-1}=p(x_k),\phantom{mm}k=1,2,\ldots
\end{equation}
If the range is finite $\{x_1,x_2,\ldots,x_n\}$ we get $F_n=1$.\\\\
\textbf{Proposition 5.2 (The Inverse Transformation Method)} Let $F$ be a distribution function that is continuous and stricly increasing. Furhter, let $U\sim\text{unif}[0,1]$ and define then random variable $Y=F^{-1}(U)$. Then $Y$ has dsitribution function $F$.\\\\
\textbf{Bevis}\\
Let $F_y$ be distribution function of $Y$ and let $x$ be in range of $Y$:
\begin{align*}
F_Y(x)&=P(F^{-1}(U)\leq x)\\
&=P(U\leq F(x))=F_U(F(x))=F(x)
\end{align*}
\textbf{Proposition 5.3 (The Rejection Method)}
\begin{enumerate}
\item Generate $Y$ and $U\sim\text{unif}[0,1]$ independent of each other.
\item If $U\leq\frac{f(Y)}{cg(Y)}$, set $X=Y$. Otherwise return to step 1.
\end{enumerate}
The random variable $X$ generated by the algorithm has pdf $f$.\\\\
\textbf{Bevis}\\
Make sure the algorithm terminates. Calculate the probability of succes:
\begin{align*}
P\left(U\leq\frac{f(Y)}{cg(Y)}\right)&=\int_R\!P\left(U\leq\frac{f(Y)}{cg(Y)}\right)g(y)\,dy\\
&=\int_R\!\frac{f(y)}{cg(y)}g(y)\,dy=\frac{1}{c}\int_R\!f(y)\,dy=\frac{1}{c}
\end{align*}
where we used the independence of $U$ and $Y$ and the fact that $U\sim\text{unif}[0,1]$. The probability of succes is $1/c$. Now we want to show that the conditional distribution of $Y$ is the same as the distribution of $X$. Use conditional probabilty:
\begin{equation}
P\left(Y\leq x|U\leq\frac{f(Y)}{cg(Y)}\right)=cP\left(Y\leq x,U\leq\frac{f(Y)}{cg(Y)}\right)
\end{equation}
With independence we get joint pdf $f(u,y)=g(y)$.
\begin{align*}
cP\left(Y\leq x,U\leq\frac{f(Y)}{cg(Y)}\right)&=c\int_{-\infty}^x\!\int_0^{f(y)/cg(y)}\!g(y)\,dy\\
&=c\int_{-\infty}^x\!\frac{f(y)}{cg(y)}g(y)\,dy=P(X\leq x)
\end{align*}













\end{document}