\documentclass[12pt,a4paper,draft]{report}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\author{Frederik Appel Vardinghus-Nielsen}
\begin{document}
\noindent\textbf{Prediction} If one is interested in a random variable $Y$ but can only observe $X$ one wants to predict $Y$ by a function of $X$, $g(X)$.\\\\
\textbf{Predictor} $g(X)$ is called a predictor.\\\\
To measure how good a predictor is the \textit{mean square error} is used.\\\\
\textbf{Mean square error} The mean square error (mse) of $g$ is
\begin{equation}
\mathrm{mse}(g)=E[(Y-g(X))^2]
\end{equation}
\textbf{Best predictor} The best predictor (with respect to minimizing the mse) is the conditional expectation $E[Y|X]$.\\\\
\textbf{Conditional variance} If $X=x$ is observed the conditional variance of $Y$ is defined as
\begin{align*}
\text{Var}[Y|X=x]&=E[(Y-E[Y|X=x])^2/|X=x]\\
\text{Var}[Y|X]&=E[(Y|X)]^2
\end{align*}
If $x$ and $Y$ are independent the conditional variance is equal to the regular variance.\\\\
\textbf{Variance from conditional variance} Calculate variance of random variable $Y$ by observing $X$.
\begin{equation}
\text{Var}[Y]=\text{Var}[E[(Y|X)]]+E[\text{Var}[(Y|X)]]
\end{equation}
\textbf{Covariance} The covariance of $X$ and $Y$ is given by
\begin{align*}
\text{Cov}[X,Y]&=E[(X-E[X])(Y-E[Y])]
\text{Cov}[X,Y]&=E[XY]-E[X]E[Y]
\end{align*}
\textbf{Independence and covariance} $X$ and $Y$ are independent $\Rightarrow\,\text{Cov}[X,Y]=0$.\\
Notice that $\Leftarrow$ does NOT apply.\\\\
\textbf{Increase and decrease of $X$ and $Y$}
\begin{itemize}
\setlength\itemsep{0em}
\item If Cov$[X,Y]>0$ then $Y$ increases if $X$ is increased.
\item If Cov$[X,Y]<0$ then $Y$ is decreased when $X$ is increased.
\end{itemize}
\textbf{Properties of the covariance}
\begin{itemize}
\item Cov$[X,X]=$Var$[X]$
\item Bilinearity
\begin{align*}
\text{Cov}[aX,bY]&=ab\, \text{Cov}[X,Y]\\
\text{Cov}[X+Y,Z]&=\text{Cov}[X,Z]+\text{Cov}[Y,Z]
\end{align*}
\end{itemize}
\textbf{Variance of in- and dependent random variables} 1 for independent and 2 for dependent
\begin{align*}
\text{1)}\phantom{mm}&\text{Var}[X,Y]=\text{Var}[X]+\text{Var}[Y]\\
\text{2)}\phantom{mm}&\text{Var}[X,Y]=\text{Var}[X]+\text{Var}[Y]+2\,\text{Cov}[X,Y]
\end{align*}
\textbf{Correlation} The correlation/correlation coefficient of $X$ and $Y$ is
\begin{equation}
\rho(X,Y)=\frac{\text{Cov}[X,Y]}{\sqrt{\text{Var}[X]\text{Var}[Y]}}
\end{equation}
\textbf{Dimensionlessness}
For $a,b\in\mathbb{R}$
\begin{equation}
\rho(aX,bY)=\frac{\text{Cov}[aX,bY]}{\sqrt{\text{Var}[aX]\text{Var}[bY]}}=\frac{\text{Cov}[X,Y]}{\sqrt{\text{Var}[X]\text{Var}[Y]}}=\rho(X,Y)
\end{equation}
\textbf{Properties of the correlation coefficient}
\begin{enumerate}
\setlength\itemsep{0em}
\item $-1\leq\rho\leq1$
\item If $X$ and $Y$ are independent, $\rho(X,Y)=0$
\item $\rho=1\,\Leftrightarrow\,Y=aX+b$ for $b\in\mathbb{R}$ and $a>0$
\item $\rho=-1\,\Leftrightarrow\,Y=aX+b$ for $b\in\mathbb{R}$ and $a<0$
\end{enumerate}
\textbf{The best linear predictor} Let $X$ and $Y$ be random variables with means $\mu_X$ and $\mu_Y$, variances $\sigma_X^2$ and $\sigma_Y^2$, and correlation coefficient $\rho$. The best linear predictor of $Y$ based on $X$ is
\begin{equation}
l(X)=\mu_Y+\rho\frac{\sigma_Y}{\sigma_X}(X-\mu_Y)
\end{equation}
\textbf{Coefficient of determination} Measures how much of the variation in $Y$ can be explained by a linear relationship of $X$.
\begin{equation}
\rho^2=\frac{\text{Var}[l(X)]}{\text{Var}[Y]}
\end{equation}
\textbf{The bivariate normal distribution} If $(X,Y)$ has joint pdf
\begin{align*}
f(x,y)=&\frac{1}{2\pi\sigma_1\sigma_2\sqrt{1-\rho^2}}\\
&\cdot\mathrm{exp}\left[-\frac{1}{2(1-\rho^2)}\left(\frac{(x-\mu_1)^2}{\sigma_1^2}+\frac{(y-\mu_2)^2}{\sigma_2^2}-\frac{2\rho(x-\mu_1)(y-\mu_2)}{\sigma_1\sigma_2}\right)\right]
\end{align*}
for $x,y\in\mathbb{R}$, then $(X,Y)$ is said to have a bivariate normal distribution.\\\\
\textbf{Properties} If $(X,Y)$ is a two-dimensional normal distribution
\begin{itemize}
\setlength\itemsep{0em}
\item $X\sim \mathcal{N}(\mu_X,\sigma_X^2);\,Y\sim\mathcal{N}(\mu_Y,\sigma_Y^2)$
\item $\rho=\rho(X,Y)$
\item $Y/X=x\sim\mathcal{N}\left(\mu_Y+\rho\frac{\sigma_Y}{\sigma_X}(x-\mu_Y),\sigma_Y^2(1-\rho^2)\right)$
\end{itemize}
Let $(X,Y)$ be a bivariate normal distribution and let $a,b\in\mathbb{R}$. Then
\begin{equation}
aX+bY\sim\mathcal{N}\left(a\mu_X+b\mu_Y,a^2\sigma_X+b^2\sigma_Y^2+2ab\,\mathrm{Cov}[X,Y]\right)
\end{equation}
If $X$ and $Y$ are independent and $X\sim\mathcal{N}(\mu_X,\sigma_X^2),\,Y\sim\mathcal{N}(\mu_Y,\sigma_Y^2)$, then for $a,b\in\mathbb{R}$
\begin{equation}
aY+bY\sim\mathcal{N}\left(a\mu_X+b\mu_Y,a^2\sigma_X^2+b^2\sigma_Y^2\right)
\end{equation}
\end{document}